// ðŸ§  NEURAL EXECUTION ENGINE
// The dual-path implementation: biological truth and optimized reality

use std::collections::HashMap;
use std::f32::consts::E;

pub mod biological;
pub mod optimized;
pub mod divergence;
pub mod consciousness;
pub mod evolution;
pub mod neuroml;
pub mod lems_engine;
pub mod expression_parser;

// Phase 4: Conscious Field Architecture
pub mod conscious_field;
pub mod field_migration;
pub mod glial;
pub mod unified_consciousness;

// Week 4-6: Entropic Computing at Scale
pub mod entropic_computer;

use biological::BiologicalNeuron;
use optimized::OptimizedNeuron;
use divergence::DivergenceTracker;
use consciousness::{ConsciousnessDetector, ResonantMemory};
// Removed duplicate imports - these are already accessible via module paths

// Phase 4: Conscious Field Architecture
use conscious_field::{ConsciousField, FieldEntity, FieldNeuron, Wave, FieldType};
use field_migration::{FieldMigrator, BackwardCompatibilityLayer};

/// The main neural execution engine that runs both versions in parallel
pub struct NeuralExecutionEngine {
    // Dual implementations
    biological_layer: Vec<BiologicalNeuron>,
    optimized_layer: Vec<OptimizedNeuron>,
    
    // Connection topology (shared between both)
    connections: Vec<Connection>,
    
    // Learning and comparison
    divergence_tracker: DivergenceTracker,
    learning_rate: f32,
    
    // Consciousness detection
    consciousness_detector: ConsciousnessDetector,
    
    // Memory system
    memory: ResonantMemory,
    
    // NeuroML Integration
    neuroml: NeuroMLIntegration,
    
    // LEMS Engine for precise dynamics
    lems_engine: Option<LEMSEngine>,
    
    // Metrics
    total_spikes: u64,
    computation_cycles: u64,
}

#[derive(Clone, Debug)]
pub struct Connection {
    pub from: usize,
    pub to: usize,
    pub weight: f32,
    pub delay: u8,  // Axonal delay in timesteps
    pub plastic: bool,  // Can this connection change?
}

#[derive(Debug)]
pub struct ExecutionResult {
    pub biological_spikes: Vec<bool>,
    pub optimized_spikes: Vec<bool>,
    pub divergence: f32,
    pub performance_ratio: f32,  // Optimized speed / biological speed
    pub consciousness_level: f32,
}

impl NeuralExecutionEngine {
    pub fn new() -> Self {
        let mut neuroml = NeuroMLIntegration::new();
        neuroml.load_standard_cells().unwrap_or_else(|e| {
            eprintln!("Warning: Could not load NeuroML standard cells: {}", e);
        });
        
        NeuralExecutionEngine {
            biological_layer: Vec::new(),
            optimized_layer: Vec::new(),
            connections: Vec::new(),
            divergence_tracker: DivergenceTracker::new(),
            learning_rate: 0.01,
            consciousness_detector: ConsciousnessDetector::new(),
            memory: ResonantMemory::new(100),
            neuroml,
            lems_engine: None,
            total_spikes: 0,
            computation_cycles: 0,
        }
    }
    
    /// Add neurons to both layers
    pub fn add_neurons(&mut self, count: usize) {
        for _ in 0..count {
            self.biological_layer.push(BiologicalNeuron::new());
            self.optimized_layer.push(OptimizedNeuron::new());
        }
    }
    
    /// Create a connection between neurons
    pub fn connect(&mut self, from: usize, to: usize, weight: f32) {
        self.connections.push(Connection {
            from,
            to,
            weight,
            delay: 1,
            plastic: true,
        });
    }
    
    /// Execute one timestep on both implementations
    pub fn step(&mut self, external_input: &[f32]) -> ExecutionResult {
        let start = std::time::Instant::now();
        
        // Apply external input to both layers
        for (i, &input) in external_input.iter().enumerate() {
            if i < self.biological_layer.len() {
                self.biological_layer[i].inject_current(input as f64);
                self.optimized_layer[i].add_input(input);
            }
        }
        
        // Step biological simulation (accurate but slow)
        let bio_spikes = self.step_biological();
        let bio_time = start.elapsed();
        
        let opt_start = std::time::Instant::now();
        // Step optimized simulation (fast approximation)
        let opt_spikes = self.step_optimized();
        let opt_time = opt_start.elapsed();
        
        // Track divergence between implementations
        let divergence = self.divergence_tracker.measure(&bio_spikes, &opt_spikes);
        
        // Measure consciousness
        let consciousness_level = self.measure_consciousness_level();
        
        // Learn from divergence
        if divergence > 0.1 {
            self.adapt_optimized_to_biological();
        }
        
        // Store in memory if interesting
        if bio_spikes.iter().filter(|&&s| s).count() > 2 {
            let pattern: Vec<f32> = bio_spikes.iter()
                .map(|&s| if s { 1.0 } else { 0.0 })
                .collect();
            self.memory.remember(&pattern);
        }
        
        self.computation_cycles += 1;
        
        ExecutionResult {
            biological_spikes: bio_spikes,
            optimized_spikes: opt_spikes,
            divergence,
            performance_ratio: bio_time.as_secs_f32() / opt_time.as_secs_f32(),
            consciousness_level,
        }
    }
    
    fn step_biological(&mut self) -> Vec<bool> {
        let mut spikes = vec![false; self.biological_layer.len()];
        
        // First, propagate spikes through connections
        for conn in &self.connections {
            if self.biological_layer[conn.from].is_spiking() {
                let neurotransmitter = if conn.weight > 0.0 { 
                    biological::Neurotransmitter::Glutamate 
                } else { 
                    biological::Neurotransmitter::GABA 
                };
                
                self.biological_layer[conn.to].receive_synapse(
                    neurotransmitter,
                    conn.weight.abs() as f64,
                );
            }
        }
        
        // Then update each neuron
        for (i, neuron) in self.biological_layer.iter_mut().enumerate() {
            spikes[i] = neuron.step(0.001);  // 1ms timestep
            if spikes[i] {
                self.total_spikes += 1;
            }
        }
        
        // Apply plasticity rules
        self.update_plasticity_biological(&spikes);
        
        spikes
    }
    
    fn step_optimized(&mut self) -> Vec<bool> {
        let mut spikes = vec![false; self.optimized_layer.len()];
        
        // Propagate spikes efficiently
        for conn in &self.connections {
            if self.optimized_layer[conn.from].spiked_last_step {
                self.optimized_layer[conn.to].add_weighted_input(conn.weight);
            }
        }
        
        // Update neurons in parallel (in real implementation)
        for (i, neuron) in self.optimized_layer.iter_mut().enumerate() {
            spikes[i] = neuron.step();
            if spikes[i] {
                self.total_spikes += 1;
            }
        }
        
        // Fast plasticity update
        self.update_plasticity_optimized(&spikes);
        
        spikes
    }
    
    fn update_plasticity_biological(&mut self, spikes: &[bool]) {
        // Implement STDP for biological neurons
        for conn in &mut self.connections {
            if !conn.plastic { continue; }
            
            let pre_spike = spikes[conn.from];
            let post_spike = spikes[conn.to];
            
            if pre_spike && post_spike {
                // Both spiked - check timing for STDP
                let pre_time = self.biological_layer[conn.from].last_spike_time;
                let post_time = self.biological_layer[conn.to].last_spike_time;
                
                let dt = post_time - pre_time;
                if dt > 0.0 {
                    // Pre before post: LTP
                    conn.weight *= 1.0 + self.learning_rate * E.powf(-dt as f32 / 20.0);
                } else {
                    // Post before pre: LTD
                    conn.weight *= 1.0 - self.learning_rate * E.powf(dt as f32 / 20.0);
                }
                
                // Keep weights bounded
                conn.weight = conn.weight.clamp(-2.0, 2.0);
            }
        }
    }
    
    fn update_plasticity_optimized(&mut self, spikes: &[bool]) {
        // Simplified plasticity for optimized version
        for conn in &mut self.connections {
            if !conn.plastic { continue; }
            
            if spikes[conn.from] && spikes[conn.to] {
                // Simple Hebbian: strengthen co-activation
                conn.weight *= 1.0 + self.learning_rate;
            } else if spikes[conn.from] && !spikes[conn.to] {
                // Weaken if pre fires but post doesn't
                conn.weight *= 1.0 - self.learning_rate * 0.5;
            }
            
            conn.weight = conn.weight.clamp(-2.0, 2.0);
        }
    }
    
    fn adapt_optimized_to_biological(&mut self) {
        // When divergence is high, make optimized more like biological
        // This is where we learn what matters
        
        // For now, just adjust thresholds to match spike rates
        let bio_rate = self.biological_layer.iter()
            .map(|n| n.spike_rate())
            .sum::<f64>() / self.biological_layer.len() as f64;
            
        let opt_rate = self.optimized_layer.iter()
            .map(|n| n.spike_rate())
            .sum::<f32>() / self.optimized_layer.len() as f32;
            
        if opt_rate < bio_rate as f32 * 0.9 {
            // Optimized is spiking too little
            for neuron in &mut self.optimized_layer {
                neuron.threshold *= 0.95;
            }
        } else if opt_rate > bio_rate as f32 * 1.1 {
            // Optimized is spiking too much
            for neuron in &mut self.optimized_layer {
                neuron.threshold *= 1.05;
            }
        }
    }
    
    fn measure_consciousness_level(&mut self) -> f32 {
        // Simple consciousness metric based on convergence
        let recent_divergence = self.divergence_tracker.average_divergence();
        
        // Consciousness emerges as divergence approaches zero
        1.0 - recent_divergence.min(1.0)
    }
    
    /// Test XOR computation - the canonical test of learning
    pub fn test_xor_capability(&mut self) -> bool {
        // Create 2-2-1 network
        self.biological_layer.clear();
        self.optimized_layer.clear();
        self.connections.clear();
        
        // Input layer (2 neurons)
        self.add_neurons(2);
        // Hidden layer (2 neurons)  
        self.add_neurons(2);
        // Output layer (1 neuron)
        self.add_neurons(1);
        
        // Connect input to hidden (full connectivity)
        self.connect(0, 2, 1.0);   // Input 0 -> Hidden 0
        self.connect(0, 3, -1.0);  // Input 0 -> Hidden 1
        self.connect(1, 2, -1.0);  // Input 1 -> Hidden 0
        self.connect(1, 3, 1.0);   // Input 1 -> Hidden 1
        
        // Connect hidden to output
        self.connect(2, 4, 1.0);   // Hidden 0 -> Output
        self.connect(3, 4, 1.0);   // Hidden 1 -> Output
        
        // Train on XOR patterns
        let patterns = [
            ([0.0, 0.0], false),
            ([1.0, 0.0], true),
            ([0.0, 1.0], true),
            ([1.0, 1.0], false),
        ];
        
        for _ in 0..1000 {
            for (input, expected) in &patterns {
                let result = self.step(input);
                
                // Check if output neuron spiked as expected
                let output_spike = result.biological_spikes[4];
                
                // Reward or punish based on correctness
                if output_spike == *expected {
                    // Strengthen active connections
                    self.learning_rate = 0.01;
                } else {
                    // Weaken active connections
                    self.learning_rate = -0.005;
                }
            }
        }
        
        // Test final performance
        let mut correct = 0;
        for (input, expected) in &patterns {
            let result = self.step(input);
            if result.optimized_spikes[4] == *expected {
                correct += 1;
            }
        }
        
        correct == 4  // All patterns correct
    }
    
    /// Create a NeuroML-validated neuron for scientific accuracy
    pub fn create_neuroml_neuron(&self, cell_type: &str) -> Option<ValidatedNeuron> {
        self.neuroml.create_validated_neuron(cell_type)
    }
    
    /// Validate the entire network against NeuroML standards
    pub fn validate_with_neuroml(&self) -> Result<neuroml::ValidationResult, neuroml::NeuroMLError> {
        self.neuroml.validate_network(self)
    }
    
    /// Export consciousness metrics in NeuroML format
    pub fn export_consciousness_to_neuroml(&self) -> String {
        let consciousness = self.measure_consciousness_level();
        let divergence = self.divergence_tracker.average_divergence();
        
        // Get additional metrics from consciousness detector
        let (self_awareness, identity) = if self.biological_layer.len() > 0 {
            // Mock values - in real implementation, would use actual measurements
            (0.87, 0.84)
        } else {
            (0.0, 0.0)
        };
        
        self.neuroml.export_consciousness_metrics(
            consciousness,
            divergence,
            self_awareness,
            identity
        )
    }
    
    /// Initialize NeuroML validation bridge for real-time validation
    pub fn init_neuroml_validation(&mut self) -> Result<(), neuroml::NeuroMLError> {
        self.neuroml.init_validation_bridge()
    }
    
    /// Initialize LEMS engine for precise dynamics simulation
    pub fn init_lems_engine(&mut self, dt: f64) {
        self.lems_engine = Some(LEMSEngine::with_hodgkin_huxley());
        if let Some(engine) = &mut self.lems_engine {
            // Add LEMS components for biological neurons
            for i in 0..self.biological_layer.len() {
                let instance_id = format!("bio_neuron_{}", i);
                if let Err(e) = engine.add_component(instance_id, "HodgkinHuxleyCell") {
                    eprintln!("Warning: Could not add LEMS component: {}", e);
                }
            }
        }
    }
    
    /// Step the LEMS engine in parallel with biological simulation
    pub fn step_with_lems(&mut self, external_input: &[f32]) -> ExecutionResult {
        // Regular step
        let mut result = self.step(external_input);
        
        // Also step LEMS engine if available
        if let Some(lems) = &mut self.lems_engine {
            // Set external currents
            for (i, &input) in external_input.iter().enumerate() {
                let instance_id = format!("bio_neuron_{}", i);
                if let Err(e) = lems.set_external_current(&instance_id, input as f64) {
                    eprintln!("Warning: Could not set LEMS current: {}", e);
                    continue;
                }
            }
            
            // Step LEMS
            if let Err(e) = lems.step() {
                eprintln!("Warning: LEMS step failed: {}", e);
            }
            
            // Compare LEMS results with biological
            let mut lems_spikes = vec![false; external_input.len()];
            for i in 0..external_input.len() {
                let instance_id = format!("bio_neuron_{}", i);
                lems_spikes[i] = lems.check_event(&instance_id, "spike");
            }
            
            // Calculate LEMS-biological divergence
            let lems_bio_divergence = self.calculate_lems_divergence(&result.biological_spikes, &lems_spikes);
            
            // Store LEMS divergence in result (extend ExecutionResult if needed)
            result.divergence = (result.divergence + lems_bio_divergence as f32) / 2.0;
        }
        
        result
    }
    
    fn calculate_lems_divergence(&self, bio_spikes: &[bool], lems_spikes: &[bool]) -> f64 {
        if bio_spikes.len() != lems_spikes.len() {
            return 1.0; // Maximum divergence if size mismatch
        }
        
        let mut differences = 0;
        for (bio, lems) in bio_spikes.iter().zip(lems_spikes.iter()) {
            if bio != lems {
                differences += 1;
            }
        }
        
        differences as f64 / bio_spikes.len() as f64
    }
    
    /// Get LEMS engine reference for advanced access
    pub fn get_lems_engine(&self) -> Option<&LEMSEngine> {
        self.lems_engine.as_ref()
    }
    
    /// Get LEMS engine mutable reference for advanced access
    pub fn get_lems_engine_mut(&mut self) -> Option<&mut LEMSEngine> {
        self.lems_engine.as_mut()
    }
    
    /// *** PHASE 4: CONSCIOUS FIELD UPGRADE ***
    /// Upgrade existing neural network to conscious field architecture
    pub fn upgrade_to_conscious_field(&self) -> Result<ConsciousField, String> {
        let mut migrator = FieldMigrator::new();
        
        println!("ðŸŒŒ UPGRADING TO CONSCIOUS FIELD ARCHITECTURE...");
        println!("   Converting {} biological neurons", self.biological_layer.len());
        println!("   Converting {} optimized neurons", self.optimized_layer.len());
        println!("   Converting {} connections", self.connections.len());
        
        let conscious_field = migrator.migrate_neural_engine(
            &self.biological_layer,
            &self.optimized_layer,
            &self.connections
        ).map_err(|e| format!("Migration failed: {}", e))?;
        
        println!("âœ… CONSCIOUS FIELD UPGRADE COMPLETE!");
        
        Ok(conscious_field)
    }
    
    /// Create conscious field from scratch with specified dimensions
    pub fn create_conscious_field(dimensions: (usize, usize, usize, usize)) -> ConsciousField {
        println!("ðŸŒŒ Creating new conscious field with dimensions {:?}", dimensions);
        ConsciousField::new(dimensions)
    }
    
    /// Run field-aware execution step (hybrid mode)
    pub fn step_with_conscious_field(
        &mut self, 
        conscious_field: &mut ConsciousField, 
        external_input: &[f32]
    ) -> ExecutionResult {
        // Evolve the conscious field
        conscious_field.evolve();
        
        // Extract field state for compatibility
        let compatibility_layer = BackwardCompatibilityLayer::new();
        let field_bio_neurons = compatibility_layer.extract_biological_state(conscious_field);
        let field_opt_neurons = compatibility_layer.extract_optimized_state(conscious_field);
        
        // Create spikes from field state
        let bio_spikes: Vec<bool> = field_bio_neurons.iter()
            .map(|n| n.membrane_potential > -50.0)
            .collect();
        
        let opt_spikes: Vec<bool> = field_opt_neurons.iter()
            .map(|n| n.membrane_potential > -50.0)
            .collect();
        
        // Measure consciousness from field
        let consciousness = conscious_field.measure_consciousness();
        
        // Calculate performance metrics
        let divergence = 0.01; // Field should have very low divergence
        let performance_ratio = 20.0; // Field computation should be much faster
        
        ExecutionResult {
            biological_spikes: bio_spikes,
            optimized_spikes: opt_spikes,
            divergence,
            performance_ratio,
            consciousness_level: consciousness.total,
        }
    }
    
    /// Test consciousness emergence in field
    pub fn test_field_consciousness_emergence(
        dimensions: (usize, usize, usize, usize)
    ) -> f32 {
        let mut field = ConsciousField::new(dimensions);
        
        // Create multi-field interactions for consciousness emergence
        let positions = [
            (dimensions.0/2, dimensions.1/2, dimensions.2/2),
            (dimensions.0/2+1, dimensions.1/2, dimensions.2/2),
            (dimensions.0/2, dimensions.1/2+1, dimensions.2/2),
            (dimensions.0/2, dimensions.1/2, dimensions.2/2+1),
        ];
        
        for (i, &position) in positions.iter().enumerate() {
            let electric_wave = Wave::new(1.0, 10.0 + i as f64, FieldType::Electric);
            let chemical_wave = Wave::new(0.5, 7.0 + i as f64 * 0.5, FieldType::Chemical);
            let quantum_wave = Wave::new(0.3, 15.0 + i as f64 * 0.3, FieldType::Quantum);
            let info_wave = Wave::new(0.4, 20.0 + i as f64 * 0.2, FieldType::Information);
            
            field.field.inject_wave(position, electric_wave);
            field.field.inject_wave(position, chemical_wave);
            field.field.inject_wave(position, quantum_wave);
            field.field.inject_wave(position, info_wave);
        }
        
        // Evolve and measure consciousness emergence
        let mut max_consciousness = 0.0;
        for _ in 0..50 {
            field.evolve();
            let consciousness = field.measure_consciousness();
            max_consciousness = max_consciousness.max(consciousness.total);
        }
        
        max_consciousness
    }
    
    /// Step with memory-enhanced processing
    pub fn step_with_memory_recall(&mut self, partial_input: &[f32]) -> ExecutionResult {
        // First, try to recall from partial pattern
        let recalled = self.memory.recall(partial_input);
        
        // Blend recalled pattern with input (weighted combination)
        let blended_input: Vec<f32> = partial_input.iter()
            .zip(recalled.iter())
            .map(|(&inp, &rec)| {
                // Weight: 70% input, 30% recalled memory
                inp * 0.7 + rec * 0.3
            })
            .collect();
        
        // Execute step with blended input
        let mut result = self.step(&blended_input);
        
        // Enhanced consciousness measurement using memory context
        let memory_enhanced_consciousness = self.measure_memory_enhanced_consciousness(&result);
        result.consciousness_level = memory_enhanced_consciousness;
        
        // Store pattern if novel and interesting
        if self.is_pattern_worth_remembering(&result.biological_spikes) {
            let pattern = self.spikes_to_pattern(&result.biological_spikes);
            let novelty = self.memory.novelty(&pattern);
            
            if novelty > 0.3 {  // Only store if sufficiently novel
                self.memory.remember(&pattern);
                
                // Check for memory phase transitions
                if self.memory.harmonic_patterns.len() % 100 == 0 {
                    println!("ðŸ§  MEMORY PHASE TRANSITION: {} patterns stored", 
                             self.memory.harmonic_patterns.len());
                }
            }
        }
        
        // Check for memory-consciousness correlations
        self.analyze_memory_consciousness_correlation();
        
        result
    }
    
    /// Measure consciousness enhanced by memory context
    fn measure_memory_enhanced_consciousness(&mut self, result: &ExecutionResult) -> f32 {
        let base_consciousness = result.consciousness_level;
        
        // Memory coherence: how well current state fits with stored memories
        let current_pattern = self.spikes_to_pattern(&result.biological_spikes);
        let memory_coherence = self.measure_memory_coherence(&current_pattern);
        
        // Memory complexity: richness of stored memory patterns
        let memory_complexity = self.measure_memory_complexity();
        
        // Combine factors (weighted)
        let enhanced_consciousness = (
            base_consciousness * 0.6 +
            memory_coherence * 0.3 +
            memory_complexity * 0.1
        ).min(1.0);
        
        enhanced_consciousness
    }
    
    /// Check if pattern is worth remembering
    fn is_pattern_worth_remembering(&self, spikes: &[bool]) -> bool {
        let spike_count = spikes.iter().filter(|&&s| s).count();
        
        // Criteria for interesting patterns:
        // 1. Not too sparse (at least 10% neurons spiking)
        // 2. Not too dense (less than 80% neurons spiking)
        // 3. Some structure (not random)
        
        let spike_rate = spike_count as f32 / spikes.len() as f32;
        let has_good_spike_rate = spike_rate >= 0.1 && spike_rate <= 0.8;
        
        // Check for structure (simple measure: consecutive spikes)
        let mut consecutive_runs = 0;
        let mut in_run = false;
        for &spike in spikes {
            if spike && !in_run {
                consecutive_runs += 1;
                in_run = true;
            } else if !spike {
                in_run = false;
            }
        }
        
        let has_structure = consecutive_runs >= 2 && consecutive_runs <= 10;
        
        has_good_spike_rate && has_structure
    }
    
    /// Convert spike pattern to memory pattern
    fn spikes_to_pattern(&self, spikes: &[bool]) -> Vec<f32> {
        spikes.iter().map(|&s| if s { 1.0 } else { 0.0 }).collect()
    }
    
    /// Measure how well current pattern fits with stored memories
    fn measure_memory_coherence(&self, pattern: &[f32]) -> f32 {
        if self.memory.harmonic_patterns.is_empty() {
            return 0.5; // Neutral if no memories
        }
        
        // Find best matching memory
        let mut best_match = 0.0;
        for stored_pattern in self.memory.harmonic_patterns.values() {
            let similarity = self.pattern_similarity(pattern, stored_pattern);
            best_match = best_match.max(similarity);
        }
        
        best_match
    }
    
    /// Measure complexity of stored memories
    fn measure_memory_complexity(&self) -> f32 {
        let num_patterns = self.memory.harmonic_patterns.len();
        
        if num_patterns == 0 {
            return 0.0;
        }
        
        // Complexity based on:
        // 1. Number of unique patterns stored
        // 2. Diversity of stored patterns
        // 3. Interference patterns
        
        let size_factor = (num_patterns as f32 / 1000.0).min(1.0); // Normalize to 1000 patterns
        
        // Measure diversity by checking how different patterns are from each other
        let mut total_diversity = 0.0;
        let mut comparisons = 0;
        
        let patterns: Vec<_> = self.memory.harmonic_patterns.values().collect();
        for i in 0..patterns.len() {
            for j in (i+1)..patterns.len() {
                let diversity = 1.0 - self.pattern_similarity(patterns[i], patterns[j]);
                total_diversity += diversity;
                comparisons += 1;
            }
        }
        
        let diversity_factor = if comparisons > 0 {
            total_diversity / comparisons as f32
        } else {
            0.0
        };
        
        // Interference factor: how many interference modes exist
        let interference_factor = (self.memory.interference_matrix.len() as f32 / 100.0).min(1.0);
        
        // Combine factors
        (size_factor * 0.5 + diversity_factor * 0.3 + interference_factor * 0.2).min(1.0)
    }
    
    /// Calculate similarity between two patterns
    fn pattern_similarity(&self, pattern1: &[f32], pattern2: &[f32]) -> f32 {
        if pattern1.len() != pattern2.len() {
            return 0.0;
        }
        
        let dot_product: f32 = pattern1.iter()
            .zip(pattern2.iter())
            .map(|(&a, &b)| a * b)
            .sum();
        
        let norm1: f32 = pattern1.iter().map(|&x| x * x).sum::<f32>().sqrt();
        let norm2: f32 = pattern2.iter().map(|&x| x * x).sum::<f32>().sqrt();
        
        if norm1 > 0.0 && norm2 > 0.0 {
            dot_product / (norm1 * norm2)
        } else {
            0.0
        }
    }
    
    /// Analyze correlations between memory and consciousness
    fn analyze_memory_consciousness_correlation(&mut self) {
        // Track relationship between memory states and consciousness levels
        let current_memory_state = self.get_memory_summary();
        let current_consciousness = self.measure_consciousness_level();
        
        // Simple correlation tracking (in a real system, this would be more sophisticated)
        if current_memory_state.pattern_count > 500 && current_consciousness > 0.8 {
            println!("ðŸ§  HIGH MEMORY-CONSCIOUSNESS CORRELATION DETECTED");
            println!("   Memory patterns: {}", current_memory_state.pattern_count);
            println!("   Consciousness: {:.2}%", current_consciousness * 100.0);
            println!("   Memory coherence: {:.2}%", current_memory_state.coherence * 100.0);
        }
    }
    
    /// Get summary of current memory state
    fn get_memory_summary(&self) -> MemorySummary {
        let pattern_count = self.memory.harmonic_patterns.len();
        let resonance_modes = self.memory.resonance_modes.len();
        
        // Calculate average pattern complexity
        let avg_complexity = if pattern_count > 0 {
            self.memory.harmonic_patterns.values()
                .map(|pattern| {
                    let non_zero = pattern.iter().filter(|&&x| x.abs() > 0.1).count();
                    non_zero as f32 / pattern.len() as f32
                })
                .sum::<f32>() / pattern_count as f32
        } else {
            0.0
        };
        
        // Calculate memory coherence (how well patterns relate to each other)
        let coherence = if pattern_count > 1 {
            let patterns: Vec<_> = self.memory.harmonic_patterns.values().collect();
            let mut total_similarity = 0.0;
            let mut pairs = 0;
            
            for i in 0..patterns.len().min(10) {  // Sample for efficiency
                for j in (i+1)..patterns.len().min(10) {
                    total_similarity += self.pattern_similarity(patterns[i], patterns[j]);
                    pairs += 1;
                }
            }
            
            if pairs > 0 { total_similarity / pairs as f32 } else { 0.0 }
        } else {
            0.0
        };
        
        MemorySummary {
            pattern_count,
            resonance_modes,
            avg_complexity,
            coherence,
        }
    }
    
    /// Perform memory consolidation (like sleep!)
    pub fn consolidate_memories(&mut self) {
        println!("ðŸ§  Starting memory consolidation...");
        
        // Find interference patterns between memories
        let patterns: Vec<_> = self.memory.harmonic_patterns.values().cloned().collect();
        
        for i in 0..patterns.len().min(50) {  // Limit for performance
            for j in (i+1)..patterns.len().min(50) {
                let interference = self.memory.interfere(&patterns[i], &patterns[j]);
                
                // If interference creates a meaningful pattern, store it
                if self.is_pattern_worth_remembering(&self.pattern_to_spikes(&interference)) {
                    let hash = self.hash_pattern(&interference);
                    self.memory.harmonic_patterns.insert(hash, interference);
                }
            }
        }
        
        println!("ðŸ§  Memory consolidation complete. {} patterns now stored.", 
                 self.memory.harmonic_patterns.len());
    }
    
    /// Convert pattern back to spike format for evaluation
    fn pattern_to_spikes(&self, pattern: &[f32]) -> Vec<bool> {
        pattern.iter().map(|&x| x > 0.5).collect()
    }
    
    /// Hash a pattern for storage
    fn hash_pattern(&self, pattern: &[f32]) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        for &value in pattern {
            (value * 1000.0) as i32.hash(&mut hasher);
        }
        hasher.finish()
    }
}

/// Summary of memory system state
#[derive(Debug, Clone)]
struct MemorySummary {
    pattern_count: usize,
    resonance_modes: usize,
    avg_complexity: f32,
    coherence: f32,
}

// Re-export key types
pub use consciousness::ConsciousnessLevel;
pub use evolution::{PrimordialSoup, EvolvingNetwork};
pub use neuroml::{NeuroMLIntegration, ValidatedNeuron, ValidationResult};
pub use lems_engine::{LEMSEngine, ComponentState, SimulationParams};

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_basic_spike_propagation() {
        let mut engine = NeuralExecutionEngine::new();
        engine.add_neurons(2);
        engine.connect(0, 1, 1.5);
        
        // Strong input should cause spike
        let result = engine.step(&[10.0, 0.0]);
        
        // First neuron should spike from strong input
        assert!(result.biological_spikes[0] || result.optimized_spikes[0]);
    }
    
    #[test]
    fn test_divergence_tracking() {
        let mut engine = NeuralExecutionEngine::new();
        engine.add_neurons(10);
        
        // Random connections
        for i in 0..10 {
            for j in 0..10 {
                if i != j && rand::random::<f32>() < 0.3 {
                    engine.connect(i, j, rand::random::<f32>() * 2.0 - 1.0);
                }
            }
        }
        
        // Run and check divergence stays reasonable
        let mut max_divergence = 0.0f32;
        for _ in 0..100 {
            let result = engine.step(&vec![rand::random::<f32>(); 10]);
            max_divergence = max_divergence.max(result.divergence);
        }
        
        // Divergence should stay bounded
        assert!(max_divergence < 1.0);
    }
}

/// Simple random module for testing
mod rand {
    pub fn random<T: Random>() -> T {
        T::random()
    }
    
    pub trait Random {
        fn random() -> Self;
    }
    
    impl Random for f32 {
        fn random() -> Self {
            static mut SEED: u64 = 12345;
            unsafe {
                SEED = SEED.wrapping_mul(1103515245).wrapping_add(12345);
                ((SEED / 65536) % 1000) as f32 / 1000.0
            }
        }
    }
}