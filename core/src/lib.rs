//! NeuronLang Core: Revolutionary Brain-Inspired Computing Substrate
//! 
//! The world's first programming language with:
//! - TRINARY computing (not binary!)
//! - DNA compression (8x memory reduction)
//! - Hierarchical memory tiers like biological brains  
//! - Fire-and-forget neurons with spike routing
//! - Loopy belief propagation for cyclic networks
//! - EWC protection against catastrophic forgetting
//! - Hardware auto-configuration for any system

pub mod dna_compression;
pub mod memory_substrate;
pub mod loopy_belief;
pub mod hardware_introspection;
pub mod ewc_fisher;
pub mod tryte;  // THE GAME CHANGER
pub mod tryte_demo;
pub mod protein_synthesis;  // Kandel's discoveries implemented!
pub mod sparse_network;  // 95% computation savings!
pub mod sparse_network_backprop;  // REAL backpropagation for sparse networks!
pub mod live_training_runner;  // Live brain training system
#[cfg(feature = "cuda")]
pub mod gpu_executor;  // REAL GPU EXECUTION!
pub mod redis_data_source;  // Live market data
#[cfg(feature = "cuda")]
pub mod cuda_raw;  // Raw CUDA bindings
#[cfg(feature = "cuda")]
pub mod gpu_native;  // Native GPU access
pub mod vulkan_compute;  // Vulkan compute shaders (works everywhere!)
pub mod vulkano_gpu;  // Production-grade Vulkano GPU acceleration
pub mod cpu_trinary_simd;  // CPU SIMD optimization
pub mod neural_morphogenesis;  // Self-adapting neural networks
pub mod universal_hardware;  // Universal hardware detection
pub mod ripple_discovery;  // Hardware boundary discovery
pub mod hoberman_architecture;  // Self-scaling neural sphere
pub mod trinary_ewc;  // Trinary-aware EWC for catastrophic forgetting prevention
pub mod continual_learning;  // Full continual learning system

// Re-export core types - HOBERMAN SPHERE FIRST!
pub use hoberman_architecture::{HobermanNeuralSphere, HobermanPlugin, SphereStats, TradingPlugin};
pub use ripple_discovery::{RippleDiscovery, Ripple};
pub use universal_hardware::{UniversalHardware, HardwareDetector, CpuArch, GpuArch};
// pub use neural_morphogenesis::{NeuralMorphogenesis, MorphogenicNetwork};

// Traditional components that plug into the sphere
pub use dna_compression::{DNACompressor, DNASequence, DNABase};
pub use memory_substrate::{MemorySubstrate, MemoryId, EWCImportance, Tier};
pub use loopy_belief::{LoopyBeliefPropagation, NeuronId as BeliefNeuronId, FactorId};
pub use hardware_introspection::{HardwareAwareSubstrate, OptimalNeuralConfig};
pub use ewc_fisher::{EWCRegularizer, ProtectedWeight, ProtectionLevel};
pub use tryte::{Tryte, TryteNeuron, TryteLayer, PackedTrytes};
pub use trinary_ewc::{TrinaryEWC, EWCStats};
pub use continual_learning::{ContinualLearner, TaskData, TaskPerformance, LearningStrategy, LearningStats};
pub use vulkan_compute::VulkanCompute;
pub use vulkano_gpu::VulkanoTrinaryNetwork;

use std::sync::Arc;

/// The complete NeuronLang brain substrate - NOW WITH HOBERMAN SPHERE!
pub struct BrainCore {
    /// THE HOBERMAN SPHERE - Auto-scaling core architecture!
    pub sphere: HobermanNeuralSphere,
    
    /// Memory hierarchy with DNA compression (plugs into sphere)
    pub memory: Arc<MemorySubstrate>,
    
    /// Loopy belief propagation for cycles (plugs into sphere)
    pub belief_network: Arc<LoopyBeliefPropagation>,
    
    /// Hardware-aware configuration (discovered by sphere)
    pub hardware: Arc<HardwareAwareSubstrate>,
    
    /// EWC protection against forgetting (sphere-aware)
    pub ewc: Arc<EWCRegularizer>,
    
    /// DNA compressor for memory efficiency (sphere-optimized)
    pub dna_compressor: Arc<DNACompressor>,
    
    /// TRINARY LAYER - Now distributed across sphere!
    pub tryte_layer: Option<TryteLayer>,
}

impl BrainCore {
    /// Create a new brain with Hoberman sphere auto-scaling core!
    pub async fn new() -> Result<Self, BrainError> {
        println!("ðŸŒ Initializing NeuronLang Brain Core with HOBERMAN SPHERE!");
        println!("ðŸ§¬ Auto-scaling trinary computing that adapts to ANY hardware!");
        
        // Step 1: Initialize the Hoberman sphere (ripple discovery + expansion)
        let sphere = HobermanNeuralSphere::initialize().await
            .map_err(|e| BrainError::HardwareConfig(e.to_string()))?;
        let stats = sphere.get_stats();
        
        println!("  ðŸŒŠ Ripple discovery complete - hardware boundaries found!");
        println!("  ðŸ”® Sphere expanded to {} neurons across memory tiers!", stats.total_neurons);
        
        // Step 2: Traditional components now plug into the sphere
        let hardware = Arc::new(HardwareAwareSubstrate::auto_configure());
        let config = hardware.get_config();
        
        // Create memory substrate with optimal sizes
        let memory = Arc::new(MemorySubstrate::new());
        
        // Initialize belief propagation with convergence settings
        let belief_network = Arc::new(LoopyBeliefPropagation::new(
            1000,  // max iterations
            0.001, // convergence threshold
        ));
        
        // Setup EWC with appropriate lambda
        let ewc = Arc::new(EWCRegularizer::new(
            0.5, // regularization strength
        ));
        
        // Create DNA compressor
        let dna_compressor = Arc::new(DNACompressor::new());
        
        println!("âœ… Hoberman-powered Brain Core initialized!");
        println!("  ðŸŒ Sphere expansion: {:.1}%", stats.expansion_level * 100.0);
        println!("  ðŸ’¾ Memory tiers: L1({}) L2({}) L3({}) RAM({})", 
                stats.l1_usage, stats.l2_usage, stats.l3_usage, stats.ram_usage);
        println!("  ðŸ”¥ Trinary computing: ENABLED & AUTO-SCALED!");
        
        Ok(Self {
            sphere,
            memory,
            belief_network,
            hardware,
            ewc,
            dna_compressor,
            tryte_layer: None,
        })
    }
    
    /// Create a Tryte layer for biological computation
    pub fn create_tryte_layer(&mut self, size: usize) {
        println!("ðŸ§¬ Creating Tryte layer with {} neurons...", size);
        self.tryte_layer = Some(TryteLayer::new(size));
        println!("  âœ“ Tryte layer ready!");
        println!("  Memory usage: {} KB for {} neurons", 
                size / 4000, size);  // 2 bits per Tryte!
    }
    
    /// Process through Tryte layer with biological efficiency
    pub fn process_trytes(&mut self, input: &[f32]) -> Vec<Tryte> {
        if let Some(ref mut layer) = self.tryte_layer {
            layer.forward(input)
        } else {
            panic!("Create Tryte layer first!");
        }
    }
    
    /// Start the brain substrate
    pub async fn start(&self) -> Result<(), BrainError> {
        println!("ðŸš€ Starting Brain Core...");
        
        // Start memory substrate
        self.memory.start()?;
        
        // Initialize belief network
        self.setup_initial_network().await?;
        
        println!("âœ… Brain Core operational!");
        Ok(())
    }
    
    /// Store a pattern with importance-based protection
    pub fn store_pattern(&self, data: Vec<f32>, importance: f32) -> MemoryId {
        let ewc_importance = EWCImportance(importance);
        let memory_id = self.memory.store_pattern(data, ewc_importance);
        
        // Update EWC if importance is high
        if importance > 0.5 {
            // This would integrate with actual gradient tracking
        }
        
        memory_id
    }
    
    /// Retrieve a pattern from any memory tier
    pub async fn retrieve_pattern(&self, memory_id: MemoryId) -> Option<Vec<f32>> {
        self.memory.retrieve_pattern(
            memory_id, 
            memory_substrate::RetrievalUrgency::Normal
        ).await
    }
    
    /// Compress weights using DNA encoding
    pub fn compress_weights(&self, weights: &[f32]) -> DNASequence {
        let mut compressor = DNACompressor::new();
        compressor.compress_weights(weights)
    }
    
    /// Run belief propagation on the network
    pub async fn propagate_beliefs(&self) -> Result<(), BrainError> {
        self.belief_network.propagate().await
            .map_err(|e| BrainError::BeliefPropagation(format!("{:?}", e)))
    }
    
    /// Setup initial belief network structure
    async fn setup_initial_network(&self) -> Result<(), BrainError> {
        // Create a simple initial network
        // This would be expanded based on actual neural architecture
        
        // Add some neurons
        for i in 0..10 {
            self.belief_network.add_neuron(BeliefNeuronId(i), 4)
                .map_err(|e| BrainError::NetworkSetup(format!("{:?}", e)))?;
        }
        
        // Add factors (connections)
        let potential = loopy_belief::FactorPotential {
            dimensions: vec![4, 4],
            values: ndarray::Array2::from_elem((4, 4), 0.25),
            is_deterministic: false,
        };
        
        // Create some connections (including cycles!)
        self.belief_network.add_factor(
            FactorId(1), 
            vec![BeliefNeuronId(0), BeliefNeuronId(1)],
            potential.clone()
        ).map_err(|e| BrainError::NetworkSetup(format!("{:?}", e)))?;
        
        self.belief_network.add_factor(
            FactorId(2),
            vec![BeliefNeuronId(1), BeliefNeuronId(2)],
            potential.clone()
        ).map_err(|e| BrainError::NetworkSetup(format!("{:?}", e)))?;
        
        // Create a cycle!
        self.belief_network.add_factor(
            FactorId(3),
            vec![BeliefNeuronId(2), BeliefNeuronId(0)],
            potential
        ).map_err(|e| BrainError::NetworkSetup(format!("{:?}", e)))?;
        
        Ok(())
    }
    
    /// Get brain statistics
    pub fn get_stats(&self) -> BrainStats {
        let memory_stats = self.memory.get_stats();
        let hardware_config = self.hardware.get_config();
        let belief_stats = self.belief_network.get_convergence_stats();
        
        let tryte_stats = self.tryte_layer.as_ref().map(|l| l.stats());
        
        BrainStats {
            total_patterns: memory_stats.total_patterns,
            memory_utilization: vec![
                memory_stats.working_utilization,
                memory_stats.short_term_utilization,
                0.0, // long-term utilization
            ],
            compression_ratio: memory_stats.average_compression_ratio,
            belief_convergence: belief_stats.converged,
            cycles_detected: belief_stats.cycles_detected,
            hardware_cores: hardware_config.num_worker_ants,
            tryte_neurons: tryte_stats.as_ref().map(|s| s.total_neurons).unwrap_or(0),
            tryte_sparsity: tryte_stats.as_ref().map(|s| s.sparsity).unwrap_or(0.0),
        }
    }
}

/// Brain statistics
#[derive(Debug)]
pub struct BrainStats {
    pub total_patterns: usize,
    pub memory_utilization: Vec<f32>, // [working, short-term, long-term]
    pub compression_ratio: f32,
    pub belief_convergence: bool,
    pub cycles_detected: usize,
    pub hardware_cores: usize,
    pub tryte_neurons: usize,
    pub tryte_sparsity: f32,
}

/// Brain core errors
#[derive(Debug)]
pub enum BrainError {
    MemoryError(String),
    BeliefPropagation(String),
    NetworkSetup(String),
    HardwareConfig(String),
}

impl std::fmt::Display for BrainError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            BrainError::MemoryError(e) => write!(f, "Memory error: {}", e),
            BrainError::BeliefPropagation(e) => write!(f, "Belief propagation error: {}", e),
            BrainError::NetworkSetup(e) => write!(f, "Network setup error: {}", e),
            BrainError::HardwareConfig(e) => write!(f, "Hardware config error: {}", e),
        }
    }
}

impl std::error::Error for BrainError {}

impl From<memory_substrate::MemoryError> for BrainError {
    fn from(e: memory_substrate::MemoryError) -> Self {
        BrainError::MemoryError(format!("{}", e))
    }
}

/// Example of using the brain core
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_brain_core_initialization() {
        let brain = BrainCore::new();
        let result = brain.start().await;
        assert!(result.is_ok());
        
        let stats = brain.get_stats();
        assert!(stats.hardware_cores > 0);
    }
    
    #[test] 
    fn test_dna_compression_integration() {
        let brain = BrainCore::new();
        
        let weights = vec![0.1, 0.2, 0.3, 0.4, 0.5];
        let compressed = brain.compress_weights(&weights);
        
        assert!(compressed.compression_ratio() > 4.0);
    }
    
    #[tokio::test]
    async fn test_memory_storage_retrieval() {
        let brain = BrainCore::new();
        brain.start().await.unwrap();
        
        let pattern = vec![1.0, 2.0, 3.0];
        let memory_id = brain.store_pattern(pattern.clone(), 0.8);
        
        tokio::time::sleep(std::time::Duration::from_millis(10)).await;
        
        let retrieved = brain.retrieve_pattern(memory_id).await;
        assert!(retrieved.is_some());
    }
    
    #[test]
    fn test_tryte_layer() {
        let mut brain = BrainCore::new();
        brain.create_tryte_layer(1000);
        
        let input = vec![0.0; 1000];  // Sparse input
        let output = brain.process_trytes(&input);
        
        assert_eq!(output.len(), 1000);
        
        // Most should be baseline (sparse)
        let baseline_count = output.iter()
            .filter(|&&t| t == Tryte::Baseline)
            .count();
        assert!(baseline_count > 900);  // >90% sparse
    }
}